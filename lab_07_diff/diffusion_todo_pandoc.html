<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>diffusion_todo</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<div id="1c652933" class="cell markdown" id="1c652933">
<h1 id="diffusion-models">Diffusion Models</h1>
<p>Diffusion models are generative models used primarily for image
synthesis and other computer vision tasks. They are trained to
<strong>progressively add random noise</strong> to data (the <em>forward
diffusion</em> process) and then <strong>learn to reverse</strong> that
process to generate high-quality samples from noise.</p>
<h2 id="before-diffusion-gans-and-vaes">Before diffusion: GANs and
VAEs</h2>
<p><strong>Generative Adversarial Networks (GANs).</strong> GANs consist
of two models trained together: a <strong>generator</strong>, which
tries to produce realistic ‚Äúfake‚Äù images, and a
<strong>discriminator</strong>, which tries to distinguish generated
images from real ones. Training is adversarial‚Äîthe generator improves by
learning to fool the discriminator.</p>
<p><strong>Variational Autoencoders (VAEs).</strong> A VAE encodes an
input image into a <strong>latent space</strong> (a low-dimensional
vector capturing salient features) and then decodes it back to
reconstruct the image. Unlike standard autoencoders, VAEs are
<strong>probabilistic</strong>: instead of encoding to a single fixed
latent vector (z), they learn a <strong>distribution</strong> over
latent variables (e.g., (p(z \mid x))) and sample from it during
training and generation.</p>
<blockquote>
<p>This exercise is not about implementing GANs or VAEs, so we won‚Äôt
dive into their details here.</p>
</blockquote>
<h3 id="further-reading">Further reading</h3>
<ul>
<li><a
href="https://www.ibm.com/think/topics/generative-adversarial-networks">What
are generative adversarial networks (GANs)?</a></li>
<li><a
href="https://www.geeksforgeeks.org/deep-learning/generative-adversarial-network-gan/">Generative
Adversarial Network (GAN) ‚Äî GeeksforGeeks</a></li>
<li><a
href="https://www.ibm.com/think/topics/variational-autoencoder">What is
a variational autoencoder?</a></li>
<li><a
href="https://www.geeksforgeeks.org/machine-learning/variational-autoencoders/">Variational
AutoEncoders ‚Äî GeeksforGeeks</a></li>
</ul>
<h2 id="rise-of-diffusion-models">Rise of diffusion models</h2>
<p>In 2020, the paper <strong><a
href="https://arxiv.org/pdf/2006.11239">Denoising Diffusion
Probabilistic Models</a></strong> introduced diffusion probabilistic
models (DDPMs), which use the diffusion mechanism to generate images.
Since then, diffusion has become one of the most popular families of
generative models. Notable examples include <strong><a
href="https://openai.com/index/video-generation-models-as-world-simulators/">SORA-1</a></strong>,
<strong><a href="https://openai.com/index/sora-2/">SORA-2</a></strong>,
<strong><a href="https://openai.com/index/dall-e-2/">DALL¬∑E
2</a></strong>, and the <strong>Stable Diffusion</strong> family.</p>
<p>You can explore thousands of stable diffusion models on <strong><a
href="https://huggingface.co/models?other=stable-diffusion">Hugging
Face</a></strong>.</p>
<p>What is interesing, there are also new types of diffusion models:
Diffusion LLMs to generate text faster then autoregresive models. Check
<a href="https://www.inceptionlabs.ai/">Inception Diffusion LLM</a>.</p>
<hr />
<p>This course mainly base on the following resources:</p>
<ul>
<li><strong>Tutorial:</strong> <a
href="https://medium.com/data-science/diffusion-model-from-scratch-in-pytorch-ddpm-9d9760528946">Diffusion
Model from Scratch in PyTorch (DDPM)</a></li>
<li><strong>Original paper:</strong> <a
href="https://arxiv.org/pdf/2006.11239">Denoising Diffusion
Probabilistic Models</a></li>
</ul>
</div>
<div id="33054dd7" class="cell code" data-execution_count="3"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-executionInfo="{&quot;elapsed&quot;:4480,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278457,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="33054dd7" data-outputId="ba44097d-799d-4e5d-8142-c6eb12fd6702">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install lightning</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Tuple</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> lightning <span class="im">as</span> L</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> sqrt</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> make_grid</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> wandb</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightning.pytorch.loggers <span class="im">import</span> WandbLogger</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightning.pytorch.callbacks <span class="im">import</span> ModelCheckpoint</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>wandb.login()  <span class="co"># Log in to your W&amp;B account</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>L.seed_everything(<span class="dv">42</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&#39;cuda&#39;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(device)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>Seed set to 42
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>cpu
</code></pre>
</div>
</div>
<div id="b0e3b08e" class="cell markdown" id="b0e3b08e">
<h1 id="diffusion-model-overview">Diffusion model overview</h1>
<p>A diffusion model has two phases:</p>
<ol>
<li><strong>Forward (diffusion) process</strong> ‚Äì gradually corrupts
clean data with noise until it becomes pure Gaussian noise.</li>
<li><strong>Reverse (denoising) process</strong> ‚Äì learns to invert that
corruption and turn noise back into data.</li>
</ol>
<hr />
<h2 id="forward-diffusion-process">Forward diffusion process</h2>
<p>The forward diffusion process takes a clean data sample <span
class="math inline"><em>x</em><sub>0</sub></span> (e.g. an image) and
step by step adds Gaussian noise until it becomes nearly pure noise
<span class="math inline"><em>x</em><sub><em>T</em></sub></span>.</p>
<p>This process is modeled as a Markov chain. That means each noisy
sample <span class="math inline"><em>x</em><sub><em>t</em></sub></span>
depends only on the previous one <span
class="math inline"><em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub></span>, not on
the full history:</p>
<p><span class="math display">$$
q(x_t \mid x_{t-1}) = \mathcal{N}\left(\sqrt{1 - \beta_t}\, x_{t-1}, \
\beta_t I \right)
$$</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline"><em>Œ≤</em><sub><em>t</em></sub></span>
controls how much noise we add at timestep <span
class="math inline"><em>t</em></span>.</li>
<li>Small <span
class="math inline"><em>Œ≤</em><sub><em>t</em></sub></span> ‚Üí a tiny
amount of noise. Large <span
class="math inline"><em>Œ≤</em><sub><em>t</em></sub></span> ‚Üí more
noise.</li>
<li>After many steps <span
class="math inline"><em>t</em>‚ÄÑ=‚ÄÑ1‚Ä¶<em>T</em></span>, the data loses
structure and becomes close to pure Gaussian noise.</li>
</ul>
<p>Instead of simulating all steps one by one, we can directly sample
the noised version at any timestep <span
class="math inline"><em>t</em></span> using a reparameterization.
Define:</p>
<ul>
<li><span
class="math inline"><em>Œ±</em><sub><em>t</em></sub>‚ÄÑ=‚ÄÑ1‚ÄÖ‚àí‚ÄÖ<em>Œ≤</em><sub><em>t</em></sub></span></li>
<li><span class="math inline">$\bar{\alpha}_t = \prod_{s=1}^{t}
\alpha_s$</span></li>
</ul>
<p>Then we can write:</p>
<p><span class="math display">$$
x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \,
\varepsilon
$$</span></p>
<p>with <span
class="math inline"><em>Œµ</em>‚ÄÑ‚àº‚ÄÑùí©(0,<em>I</em>)</span>.</p>
<p><strong>Interpretation:</strong></p>
<ul>
<li><span class="math inline"><em>Œ±ÃÑ</em><sub><em>t</em></sub></span>
acts like a signal-to-noise ratio at step <span
class="math inline"><em>t</em></span>.
<ul>
<li>Early (small <span class="math inline"><em>t</em></span>): <span
class="math inline"><em>Œ±ÃÑ</em><sub><em>t</em></sub>‚ÄÑ‚âà‚ÄÑ1</span> ‚Üí mostly
clean signal.</li>
<li>Late (large <span class="math inline"><em>t</em></span>): <span
class="math inline"><em>Œ±ÃÑ</em><sub><em>t</em></sub>‚ÄÑ‚âà‚ÄÑ0</span> ‚Üí mostly
noise.</li>
</ul></li>
<li>This closed-form lets us sample <span
class="math inline"><em>x</em><sub><em>t</em></sub></span> at any
timestep <span class="math inline"><em>t</em></span> in one shot,
without running every previous step. This is important for training
efficiency.</li>
</ul>
<hr />
<h2 id="reverse-diffusion-process">Reverse diffusion process</h2>
<p>The reverse diffusion process is the generative step. We start from
pure noise <span
class="math inline"><em>x</em><sub><em>T</em></sub>‚ÄÑ‚àº‚ÄÑùí©(0,<em>I</em>)</span>
and try to iteratively denoise it back into something that looks like
real data.</p>
<p>In an ideal world, we would sample</p>
<p><span
class="math display"><em>q</em>(<em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub>‚à£<em>x</em><sub><em>t</em></sub>)</span></p>
<p>which answers: ‚Äúgiven this noisy image <span
class="math inline"><em>x</em><sub><em>t</em></sub></span>, what should
the slightly cleaner image <span
class="math inline"><em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub></span> look
like?‚Äù</p>
<p>But the true reverse distribution <span
class="math inline"><em>q</em>(<em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub>‚à£<em>x</em><sub><em>t</em></sub>)</span>
is intractable: technically solvable, but requiring infinite time to
compute.</p>
<p>So instead we train a neural network <span
class="math inline"><em>Œµ</em><sub><em>Œ∏</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>)</span>
to predict the noise that was added at step <span
class="math inline"><em>t</em></span>. If we know the noise, we can
remove it and step from <span
class="math inline"><em>x</em><sub><em>t</em></sub></span> to an
estimate of <span
class="math inline"><em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub></span>. This
defines a learned reverse process</p>
<p><span
class="math display"><em>p</em><sub><em>Œ∏</em></sub>(<em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub>‚à£<em>x</em><sub><em>t</em></sub>)</span></p>
<p>which we use to walk backward from <span
class="math inline"><em>x</em><sub><em>T</em></sub></span> to something
that looks like <span
class="math inline"><em>x</em><sub>0</sub></span>.</p>
<p><strong>Intuition:</strong></p>
<ul>
<li>Forward: slowly add noise.</li>
<li>Reverse: learn how to remove that noise step by step.</li>
<li>After training, we can generate a <em>new</em> image by starting
from random noise and denoising repeatedly.</li>
</ul>
<hr />
<h2 id="loss-function-for-training">Loss function for training</h2>
<p>Training tries to make the learned reverse process <span
class="math inline"><em>p</em><sub><em>Œ∏</em></sub></span> match the
true forward process <span class="math inline"><em>q</em></span>. The
full derivation is written as a variational lower bound (VLB) and
involves KL divergences between Gaussians at each step.</p>
<p>It is commonly described in terms of three terms: <span
class="math inline"><em>L</em><sub><em>T</em></sub></span>, <span
class="math inline"><em>L</em><sub><em>t</em></sub></span>, and <span
class="math inline"><em>L</em><sub>0</sub></span>.</p>
<ul>
<li><p><strong><span
class="math inline"><em>L</em><sub><em>T</em></sub></span></strong><br />
KL divergence between <span
class="math inline"><em>q</em>(<em>x</em><sub><em>T</em></sub>‚à£<em>x</em><sub>0</sub>)</span>
and <span
class="math inline"><em>p</em><sub><em>Œ∏</em></sub>(<em>x</em><sub><em>T</em></sub>)</span>.<br />
Intuition: does the model's starting distribution at <span
class="math inline"><em>t</em>‚ÄÑ=‚ÄÑ<em>T</em></span> match pure Gaussian
noise?<br />
This can usually be treated as a constant because <span
class="math inline"><em>x</em><sub><em>T</em></sub></span> is basically
standard Gaussian.</p></li>
<li><p><strong><span
class="math inline"><em>L</em><sub><em>t</em></sub></span></strong><br />
KL divergence between the <em>true</em> reverse step <span
class="math inline"><em>q</em>(<em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub>‚à£<em>x</em><sub><em>t</em></sub>,<em>x</em><sub>0</sub>)</span>
and the <em>learned</em> reverse step <span
class="math inline"><em>p</em><sub><em>Œ∏</em></sub>(<em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub>‚à£<em>x</em><sub><em>t</em></sub>)</span>.<br />
This measures how well the model denoises at each timestep.</p></li>
<li><p><strong><span
class="math inline"><em>L</em><sub>0</sub></span></strong><br />
Negative log-likelihood of reconstructing the original sample <span
class="math inline"><em>x</em><sub>0</sub></span> from <span
class="math inline"><em>x</em><sub>1</sub></span>:<br />
<span
class="math inline">‚ÄÖ‚àí‚ÄÖlog‚ÄÜ<em>p</em><sub><em>Œ∏</em></sub>(<em>x</em><sub>0</sub>‚à£<em>x</em><sub>1</sub>)</span>.<br />
This tells us how well the final denoised output matches real
data.</p></li>
</ul>
<hr />
<h3 id="practical-simplification">Practical simplification</h3>
<p>All of that math can be simplified to a very convenient training
loss.</p>
<p>During training we:</p>
<ol>
<li>Take a real sample <span
class="math inline"><em>x</em><sub>0</sub></span>.</li>
<li>Sample a random timestep <span
class="math inline"><em>t</em></span>.</li>
<li>Generate <span
class="math inline"><em>x</em><sub><em>t</em></sub></span> using the
closed form <span class="math display">$$
x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \,
\varepsilon
$$</span> with known noise <span
class="math inline"><em>Œµ</em></span>.</li>
<li>Ask the model to predict that noise: <span
class="math inline"><em>Œµ</em><sub><em>Œ∏</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>)</span>.</li>
</ol>
<p>Then we optimize a simple mean squared error (MSE):</p>
<p><span
class="math display">‚Ñí<sub>simple</sub>(<em>Œ∏</em>)‚ÄÑ=‚ÄÑùîº<sub><em>t</em>,‚ÄÜ<em>x</em><sub>0</sub>,‚ÄÜ<em>Œµ</em></sub>[‚à•<em>Œµ</em>‚ÄÖ‚àí‚ÄÖ<em>Œµ</em><sub><em>Œ∏</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>)‚à•<sup>2</sup>]</span></p>
<p>So the model is literally trained to answer:<br />
<strong>"What noise was added here?"</strong></p>
<hr />
<h2 id="important-to-remember">Important to remember</h2>
<p><img src = "https://raw.githubusercontent.com/vision-agh/DNN-Course-media/refs/heads/main/lab8_diffusion/figures/algorithms.png" alt="Algorithms" width="600"></p>
<ul>
<li><p><strong>Forward (diffusion) process:</strong><br />
We corrupt clean data into noise: <span class="math display">$$
x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \,
\varepsilon
$$</span> where <span
class="math inline"><em>Œ±ÃÑ</em><sub><em>t</em></sub></span> decreases
over time ‚Üí less signal, more noise ‚Üí <span
class="math inline"><em>x</em><sub><em>T</em></sub></span> is almost
pure Gaussian noise.</p></li>
<li><p><strong>Reverse (denoising) process:</strong><br />
A neural network predicts the noise <span
class="math inline"><em>Œµ</em><sub><em>Œ∏</em></sub>(<em>x</em><sub><em>t</em></sub>,<em>t</em>)</span>
so we can remove it and step from <span
class="math inline"><em>x</em><sub><em>t</em></sub></span> to <span
class="math inline"><em>x</em><sub><em>t</em>‚ÄÖ‚àí‚ÄÖ1</sub></span>.
Repeating this turns random noise into a realistic sample.</p></li>
<li><p><strong>Training loop (per batch image):</strong></p>
<ol>
<li>Sample timestep <span class="math inline"><em>t</em></span>.</li>
<li>Create a noisy version <span
class="math inline"><em>x</em><sub><em>t</em></sub></span> from <span
class="math inline"><em>x</em><sub>0</sub></span>.</li>
<li>Train the model to predict the noise that was added.</li>
</ol></li>
<li><p><strong>Sampling / generation:</strong></p>
<ol>
<li>Start from random Gaussian noise.</li>
<li>Apply the model step by step to denoise.</li>
<li>After all steps, you get a generated image.</li>
</ol></li>
</ul>
<p><strong>Core idea:</strong> diffusion learns how to undo noise.</p>
</div>
<div id="26042bab" class="cell markdown" id="26042bab">
<h3 id="implementation">Implementation</h3>
<p>Let's start by implementing the
<strong><code>DDPM_Scheduler</code></strong> class. This class will
initialize the parameters <span class="math inline"><em>Œ≤</em></span>
and <span class="math inline"><em>Œ±ÃÇ</em></span> used during training and
sampling.</p>
<p>In the original DDPM paper, <em>Ho et al.</em> used a <strong>linear
variance schedule</strong> with 1,000 steps, where <span
class="math inline"><em>Œ≤</em><sub>1</sub>‚ÄÑ=‚ÄÑ1‚ÄÖ√ó‚ÄÖ10<sup>‚àí4</sup></span>
and <span
class="math inline"><em>Œ≤</em><sub><em>T</em></sub>‚ÄÑ=‚ÄÑ0.02</span>. Later
studies found that alternative schedules ‚Äî such as <strong>cosine
schedules</strong> or even <strong>learned schedules</strong> ‚Äî can
improve both performance and efficiency. But we will focus on basic
one.</p>
<p><strong>Steps to implement:</strong></p>
<ol>
<li>Initialize <code>self.beta</code> as a linearly spaced tensor
(<code>torch.linspace</code>) over the number of timesteps, ranging from
<code>1e-4</code> to <code>0.02</code>.</li>
<li>Compute <span
class="math inline"><em>Œ±</em>‚ÄÑ=‚ÄÑ1‚ÄÖ‚àí‚ÄÖ<em>Œ≤</em></span>.</li>
<li>Initialize <code>self.alpha</code> as the <strong>cumulative
product</strong> of <span class="math inline"><em>Œ±</em></span> using
<code>torch.cumprod</code>. Set requires_grad as
<code>False</code>.</li>
</ol>
<p>We can define <code>forward</code> function, that takes parameter
<code>t</code> and returns <code>self.beta</code> and
<code>self.alpha</code> for timestamp <code>t</code>.</p>
</div>
<div id="5396aeb2" class="cell code" data-execution_count="4"
data-executionInfo="{&quot;elapsed&quot;:6,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278484,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="5396aeb2">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DDPM_Scheduler(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_time_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta <span class="op">=</span> torch.linspace(<span class="fl">1e-4</span>, <span class="fl">0.02</span>, num_time_steps)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> torch.cumprod(alpha, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure these tensors don&#39;t require gradients</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta.requires_grad_(<span class="va">False</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha.requires_grad_(<span class="va">False</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, t):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.beta[t], <span class="va">self</span>.alpha[t]</span></code></pre></div>
</div>
<div id="65153f6e" class="cell markdown" id="65153f6e">
<h2 id="model-architecture-implementation-notes">Model architecture
(implementation notes)</h2>
<p>We now define the denoising network. Following the DDPM paper, the
core model is a <strong>U-Net</strong> with:</p>
<ul>
<li><strong>Residual convolutional blocks</strong> (Wide-ResNet‚Äìstyle):
two <span class="math inline">3‚ÄÖ√ó‚ÄÖ3</span> convs per block,
<strong>GroupNorm</strong> instead of BatchNorm, <strong>SiLU</strong>
nonlinearity, and <strong>Dropout</strong>.</li>
<li><strong>Self-attention blocks</strong> at lower spatial resolutions
(e.g., at <span class="math inline">16‚ÄÖ√ó‚ÄÖ16</span> for inputs of <span
class="math inline">32‚ÄÖ√ó‚ÄÖ32</span> or <span
class="math inline">256‚ÄÖ√ó‚ÄÖ256</span>). Attention helps the model capture
long-range dependencies that plain convolutions might miss.</li>
</ul>
<p>We‚Äôll first implement two building blocks:</p>
<ol>
<li><code>ResnetBlock2D</code> ‚Äî a residual conv block that also injects
<strong>time embeddings</strong>.</li>
<li><code>AttentionBlock</code> ‚Äî a 2D self-attention block applied
between down/up conv stages.</li>
</ol>
<hr />
<h3
id="resnetblock2d--residual-block-with-time-embedding"><code>ResnetBlock2D</code>
‚Äî residual block with time embedding</h3>
<p><strong>Constructor arguments.</strong></p>
<ul>
<li><code>C_in</code> <em>(int)</em>: input channel dimension.<br />
</li>
<li><code>C_out</code> <em>(int)</em>: output channel dimension.<br />
</li>
<li><code>C_emb</code> <em>(int)</em>: dimension of the <strong>time
embedding</strong> that will be injected (described later).<br />
</li>
<li><code>num_groups</code> <em>(int)</em>: number of groups for
<code>GroupNorm</code>.<br />
</li>
<li><code>dropout_p</code> <em>(float)</em>: dropout probability (e.g.,
<code>0.1</code> or <code>0.2</code>).</li>
</ul>
<p><strong>Layers inside.</strong></p>
<ul>
<li><code>GroupNorm(C_in)</code> ‚Üí
<code>Conv2d(C_in, C_out, 3√ó3, padding=1)</code><br />
</li>
<li><code>Linear(C_emb ‚Üí C_out)</code> to project the time
embedding<br />
</li>
<li><code>GroupNorm(C_out)</code> ‚Üí <code>Dropout(p=dropout_p)</code> ‚Üí
<code>Conv2d(C_out, C_out, 3√ó3, padding=1)</code><br />
</li>
<li><code>SiLU(inplace = True)</code> nonlinearity after each
normalization (pre-activation style)</li>
</ul>
<p><strong>Forward pass.</strong></p>
<ol>
<li>Normalize and activate the input.</li>
<li>First conv.</li>
<li>Inject time embedding:
<ul>
<li>Project: <code>emb = Linear(time_emb)</code></li>
<li>Broadcast and add: <code>h = h + emb[:, :, None, None]</code></li>
</ul></li>
<li>Normalize ‚Üí dropout ‚Üí activate ‚Üí second conv:<br />
</li>
<li>Residual add if <code>in</code> and <code>out</code> shapes match,
else return output from second conv.</li>
</ol>
</div>
<div id="4b1676f2" class="cell code" data-execution_count="5"
data-executionInfo="{&quot;elapsed&quot;:6,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278511,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="4b1676f2">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResnetBlock2D(nn.Module):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>                 C_in: <span class="bu">int</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>                 C_out: <span class="bu">int</span>,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>                 C_emb: <span class="bu">int</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>                 num_groups: <span class="bu">int</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                 dropout_p: <span class="bu">float</span>):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm1 <span class="op">=</span> nn.GroupNorm(num_groups, C_in)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(C_in, C_out, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time_emb_proj <span class="op">=</span> nn.Linear(C_emb, C_out)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm2 <span class="op">=</span> nn.GroupNorm(num_groups, C_out)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(C_out, C_out, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout_p)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nonlinearity <span class="op">=</span> nn.SiLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, embeddings):</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> x</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.norm1(h)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.nonlinearity(h)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.conv1(h)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> <span class="va">self</span>.time_emb_proj(embeddings)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> h <span class="op">+</span> embeddings[:, :, <span class="va">None</span>, <span class="va">None</span>]</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.norm2(h)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.dropout(h)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.nonlinearity(h)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.conv2(h)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> h <span class="op">+</span> x <span class="cf">if</span> h.shape <span class="op">==</span> x.shape <span class="cf">else</span> h</span></code></pre></div>
</div>
<div id="a7e3a897" class="cell markdown" id="a7e3a897">
<h3
id="attentionblock--multi-head-self-attention-for-2d-features"><code>AttentionBlock</code>
‚Äî multi-head self-attention for 2D features</h3>
<p><strong>Constructor arguments.</strong></p>
<ul>
<li><code>C</code> <em>(int)</em>: channel dimension for
input/output.<br />
</li>
<li><code>num_heads</code> <em>(int)</em>: number of attention heads;
must divide <code>C</code>.<br />
</li>
<li><code>num_groups</code> <em>(int)</em>: number of groups for
<code>GroupNorm</code>.<br />
</li>
<li><code>dropout_p</code> <em>(float)</em>: attention dropout
probability.</li>
</ul>
<p><strong>Layers inside.</strong></p>
<ul>
<li><code>GroupNorm(num_groups, C)</code><br />
</li>
<li><code>Linear(C ‚Üí C)</code> for <strong>query</strong>,
<strong>key</strong>, and <strong>value</strong> projections (separate
layers)<br />
</li>
<li><code>Linear(C ‚Üí C)</code> output projection
(<code>proj_attn</code>)</li>
</ul>
<p><strong>Forward pass.</strong></p>
<ol>
<li>Normalize the input.<br />
</li>
<li>Flatten spatial dims for QKV: first use <code>.view</code> to merge
<code>H*W</code> into <code>L</code>, then <code>.permute</code> to get
<code>(B, L, C)</code> from <code>(B, C, H, W)</code>.<br />
</li>
<li>Project to Q, K, V using <code>x_flat</code> and the linear
layers.<br />
</li>
<li>Reshape for multi-head attention:
<code>.view(B, L, num_heads, head_dim)</code> then
<code>.permute(0, 2, 1, 3)</code> to obtain
<code>(B, num_heads, L, head_dim)</code>.<br />
</li>
<li>Compute attention with
<code>F.scaled_dot_product_attention(q, k, v, dropout_p=dropout_p, is_causal=False)</code>.<br />
</li>
<li>Combine heads: <code>.permute(0, 2, 1, 3).contiguous()</code> back
to <code>(B, L, num_heads, head_dim)</code>, then
<code>.view(B, L, C)</code>.<br />
</li>
<li>Project the merged attention using the <code>proj_attn</code> linear
layer.<br />
</li>
<li>Unflatten to the image shape: <code>.permute(0, 2, 1)</code> to
<code>(B, C, L)</code>, then <code>.reshape(B, C, H, W)</code>.</li>
</ol>
</div>
<div id="0ecd788e" class="cell code" data-execution_count="6"
data-executionInfo="{&quot;elapsed&quot;:48,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278585,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="0ecd788e">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionBlock(nn.Module):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, C: <span class="bu">int</span>, num_heads: <span class="bu">int</span>, num_groups: <span class="bu">int</span>, dropout_p: <span class="bu">float</span>):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> C <span class="op">%</span> num_heads <span class="op">==</span> <span class="dv">0</span>, <span class="st">&quot;C must be divisible by num_heads&quot;</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head_dim <span class="op">=</span> C <span class="op">//</span> num_heads</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout_p <span class="op">=</span> dropout_p</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.group_norm <span class="op">=</span> nn.GroupNorm(num_groups, C)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.query <span class="op">=</span> nn.Linear(C, C)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.key <span class="op">=</span> nn.Linear(C, C)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> nn.Linear(C, C)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj_attn <span class="op">=</span> nn.Linear(C, C)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (B, C, H, W) - input feature map</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co">            out: (B, C, H, W)</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        B, C, H, W <span class="op">=</span> x.shape</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        x_norm <span class="op">=</span> <span class="va">self</span>.group_norm(x)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Flatten spatial dims: (B, C, H, W) -&gt; (B, H*W, C)</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        x_flat <span class="op">=</span> x_norm.view(B, C, H <span class="op">*</span> W).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>        L <span class="op">=</span> x_flat.shape[<span class="dv">1</span>]</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.query(x_flat)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.key(x_flat)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.value(x_flat)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape for multi-head attention: (B, L, C) -&gt; (B, num_heads, L, head_dim)</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> q.view(B, L, <span class="va">self</span>.num_heads, <span class="va">self</span>.head_dim).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> k.view(B, L, <span class="va">self</span>.num_heads, <span class="va">self</span>.head_dim).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.view(B, L, <span class="va">self</span>.num_heads, <span class="va">self</span>.head_dim).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute scaled dot-product attention</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>        attn <span class="op">=</span> F.scaled_dot_product_attention(q, k, v, dropout_p<span class="op">=</span><span class="va">self</span>.dropout_p, is_causal<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine heads: (B, num_heads, L, head_dim) -&gt; (B, L, C)</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        attn <span class="op">=</span> attn.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>).contiguous().view(B, L, C)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>        x_out <span class="op">=</span> <span class="va">self</span>.proj_attn(attn)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape back to image: (B, L, C) -&gt; (B, C, H, W)</span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>        x_out <span class="op">=</span> x_out.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>).reshape(B, C, H, W)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x_out</span></code></pre></div>
</div>
<div id="5a957781" class="cell markdown" id="5a957781">
<p>Now, using our ResNet and Attention block we will implement larger
block for our U-Net, more precisly, DownBlock2D, UpBlock2D and
MidBlock2D.</p>
<h3
id="downblock2d--encoder-stage-with-optional-attention"><code>DownBlock2D</code>
‚Äî encoder stage with optional attention</h3>
<p><strong>Constructor arguments.</strong></p>
<ul>
<li><code>C_in</code> <em>(int)</em>: input channels.<br />
</li>
<li><code>C_out</code> <em>(int)</em>: output channels after this
stage.<br />
</li>
<li><code>C_emb</code> <em>(int)</em>: time-embedding dimension passed
to <code>ResnetBlock2D</code>.<br />
</li>
<li><code>num_groups</code> <em>(int)</em>: number of groups for
<code>GroupNorm</code>.<br />
</li>
<li><code>dropout_p</code> <em>(float)</em>: dropout probability in
residual blocks.<br />
</li>
<li><code>use_attn</code> <em>(bool)</em>: whether to insert an
<code>AttentionBlock</code>.</li>
</ul>
<p><strong>Layers inside.</strong></p>
<ul>
<li><code>ResnetBlock2D(C_in ‚Üí C_out)</code><br />
</li>
<li><code>ResnetBlock2D(C_out ‚Üí C_out)</code><br />
</li>
<li><code>AttentionBlock(C_out, num_head=8)</code> <em>or</em>
<code>Identity</code> (controlled by <code>use_attn</code>)<br />
</li>
<li>Downsample:
<code>Conv2d(C_out ‚Üí C_out, kernel=3, stride=2, pad=1)</code></li>
</ul>
<p><strong>Forward pass.</strong></p>
<ol>
<li>Apply two residual blocks with time conditioning.<br />
</li>
<li>Apply attention.<br />
</li>
<li>Save the current feature map as <strong><code>skip</code></strong>
for the U-Net skip connection.<br />
</li>
<li>Downsample with a stride-2 conv.<br />
</li>
<li>Return <code>(x, skip)</code>.</li>
</ol>
</div>
<div id="1dd001cc" class="cell code" data-execution_count="7"
data-executionInfo="{&quot;elapsed&quot;:59,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278606,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="1dd001cc">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DownBlock2D(nn.Module):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                 C_in,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                 C_out,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                 C_emb,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                 num_groups,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>                 dropout_p,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>                 use_attn<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_attn <span class="op">=</span> use_attn</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res1 <span class="op">=</span> ResnetBlock2D(C_in, C_out, C_emb, num_groups, dropout_p)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res2 <span class="op">=</span> ResnetBlock2D(C_out, C_out, C_emb, num_groups, dropout_p)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_attn:</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attn <span class="op">=</span> AttentionBlock(C_out, num_heads<span class="op">=</span><span class="dv">8</span>, num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_p)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attn <span class="op">=</span> nn.Identity()</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down <span class="op">=</span> nn.Conv2d(C_out, C_out, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res1(x, emb)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res2(x, emb)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attn(x)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        skip <span class="op">=</span> x</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.down(x)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x, skip</span></code></pre></div>
</div>
<div id="e859b1e8" class="cell markdown" id="e859b1e8">
<h3
id="upblock2d--decoder-stage-with-skip-fusion-and-optional-attention"><code>UpBlock2D</code>
‚Äî decoder stage with skip fusion and optional attention</h3>
<p><strong>Constructor arguments.</strong></p>
<ul>
<li><code>C_in</code> <em>(int)</em>: channels of the incoming
<strong>upsampled</strong> stream.<br />
</li>
<li><code>C_skip</code> <em>(int)</em>: channels from the encoder skip
tensor (to be concatenated).<br />
</li>
<li><code>C_out</code> <em>(int)</em>: output channels after this
stage.<br />
</li>
<li><code>C_emb</code> <em>(int)</em>: time-embedding dimension for
<code>ResnetBlock2D</code>.<br />
</li>
<li><code>num_groups</code> <em>(int)</em>: number of groups for
<code>GroupNorm</code>.<br />
</li>
<li><code>dropout_p</code> <em>(float)</em>: dropout probability in
residual blocks.<br />
</li>
<li><code>use_attn</code> <em>(bool)</em>: whether to insert an
<code>AttentionBlock</code>.</li>
</ul>
<p><strong>Layers inside.</strong></p>
<ul>
<li>Upsample <code>up</code>: Sequential with
<code>Upsample(scale_factor=2, mode="nearest")</code> ‚Üí
<code>Conv2d(C_in ‚Üí C_in, 3√ó3, pad=1)</code><br />
</li>
<li><code>ResnetBlock2D(C_in + C_skip ‚Üí C_out)</code><br />
</li>
<li><code>ResnetBlock2D(C_out ‚Üí C_out)</code><br />
</li>
<li><code>AttentionBlock(C_out, num_heads=8)</code> <em>or</em>
<code>Identity</code> (controlled by <code>use_attn</code>)</li>
</ul>
<p><strong>Forward pass.</strong></p>
<ol>
<li>Upsample the input stream (nearest) and smooth with a 3√ó3
conv.<br />
</li>
<li>If spatial sizes differ from the skip tensor
<code>(x.shape[-2:] != skip.shape[-2:])</code>, <strong>resize</strong>
with bilinear interpolation to match
<code>(F.interpolate(x, size=skip.shape[-2:], mode="bilinear", align_corners=False))</code>.<br />
</li>
<li>Concatenate channels: <code>cat([x, skip], dim=1)</code>.<br />
</li>
<li>Apply two residual blocks with time conditioning.<br />
</li>
<li>Apply attention.<br />
</li>
<li>Return the refined feature map.</li>
</ol>
</div>
<div id="2cfc74f9" class="cell code" data-execution_count="8"
data-executionInfo="{&quot;elapsed&quot;:56,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278610,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="2cfc74f9">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UpBlock2D(nn.Module):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                 C_in,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>                 C_skip,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>                 C_out,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                 C_emb,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                 num_groups,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                 dropout_p,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>                 use_attn<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_attn <span class="op">=</span> use_attn</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Upsample: nearest neighbor + convolution</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up <span class="op">=</span> nn.Sequential(</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>            nn.Upsample(scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">&quot;nearest&quot;</span>),</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(C_in, C_in, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First resnet block takes concatenated input (C_in + C_skip) -&gt; C_out</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res1 <span class="op">=</span> ResnetBlock2D(C_in <span class="op">+</span> C_skip, C_out, C_emb, num_groups, dropout_p)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Second resnet block maintains channels C_out -&gt; C_out</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res2 <span class="op">=</span> ResnetBlock2D(C_out, C_out, C_emb, num_groups, dropout_p)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Conditional attention</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_attn:</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attn <span class="op">=</span> AttentionBlock(C_out, num_heads<span class="op">=</span><span class="dv">8</span>, num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_p)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attn <span class="op">=</span> nn.Identity()</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, skip, emb):</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.up(x)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># safety resize if needed</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x.shape[<span class="op">-</span><span class="dv">2</span>:] <span class="op">!=</span> skip.shape[<span class="op">-</span><span class="dv">2</span>:]:</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> F.interpolate(x, size<span class="op">=</span>skip.shape[<span class="op">-</span><span class="dv">2</span>:], mode<span class="op">=</span><span class="st">&quot;bilinear&quot;</span>, align_corners<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat([x, skip], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res1(x, emb)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res2(x, emb)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attn(x)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div id="08d8ad17" class="cell markdown" id="08d8ad17">
<h3 id="midblock2d--bottleneck-with-attention"><code>MidBlock2D</code> ‚Äî
bottleneck with attention</h3>
<p><strong>Constructor arguments.</strong></p>
<ul>
<li><code>C</code> <em>(int)</em>: channel dimension throughout the mid
block.<br />
</li>
<li><code>C_emb</code> <em>(int)</em>: time-embedding dimension for
<code>ResnetBlock2D</code>.<br />
</li>
<li><code>num_groups</code> <em>(int)</em>: number of groups for
<code>GroupNorm</code>.<br />
</li>
<li><code>dropout_p</code> <em>(float)</em>: dropout probability in
residual blocks.</li>
</ul>
<p><strong>Layers inside.</strong></p>
<ul>
<li><code>ResnetBlock2D(C ‚Üí C)</code><br />
</li>
<li><code>AttentionBlock(C, num_heads=8)</code><br />
</li>
<li><code>ResnetBlock2D(C ‚Üí C)</code></li>
</ul>
<p><strong>Forward pass.</strong></p>
<ol>
<li>Residual block with time conditioning.<br />
</li>
<li>Self-attention to inject global context.<br />
</li>
<li>Second residual block with time conditioning.<br />
</li>
<li>Return the bottleneck features.</li>
</ol>
</div>
<div id="87339c95" class="cell code" data-execution_count="9"
data-executionInfo="{&quot;elapsed&quot;:39,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278613,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="87339c95">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MidBlock2D(nn.Module):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, C, C_emb, num_groups, dropout_p):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res1 <span class="op">=</span> ResnetBlock2D(C, C, C_emb, num_groups, dropout_p)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> AttentionBlock(C, num_heads<span class="op">=</span><span class="dv">8</span>, num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_p)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res2 <span class="op">=</span> ResnetBlock2D(C, C, C_emb, num_groups, dropout_p)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res1(x, emb)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attn(x)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res2(x, emb)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div id="c42dec6c" class="cell markdown" id="c42dec6c">
<h3 id="time-embeddings--providing-timestep-information">Time embeddings
‚Äî providing timestep information</h3>
<p>The last part of our implementation is the <strong>time
embedding</strong>, which provides each <code>ResnetBlock2D</code> with
information about the current diffusion timestep.<br />
This helps the model understand <strong>how much noise</strong> is
present in the input and <strong>how aggressively</strong> it should
denoise.<br />
While not strictly required, adding time embeddings makes training
<strong>more stable</strong> and generally improves the results.</p>
<hr />
<h3 id="sinusoidalembeddings"><code>SinusoidalEmbeddings</code></h3>
<p>We define a class <code>SinusoidalEmbeddings</code>, similar to the
<strong>positional encodings</strong> used in Transformers.<br />
It maps a timestep index <code>t</code> to a continuous embedding vector
that captures temporal information.</p>
<p><strong>Constructor arguments.</strong></p>
<ul>
<li><code>num_time_steps</code> <em>(int)</em>: total number of
diffusion steps (e.g., 1,000).<br />
</li>
<li><code>embed_dim</code> <em>(int)</em>: dimension of the generated
embedding vector.</li>
</ul>
<p><strong>Forward pass.</strong></p>
<ul>
<li>Takes the current timestep <code>t</code> (shape <code>[B]</code> or
<code>[B, 1]</code>).</li>
<li>Returns the embedding tensor, moved to the same device as
<code>t</code>.</li>
</ul>
<p><strong>Note.</strong><br />
In this implementation, we do <strong>not</strong> need additional
positional embeddings inside the self-attention layers.<br />
Since each attention block is preceded by convolutional layers, those
already provide strong <strong>spatial positional informations</strong>
for the image patches.</p>
</div>
<div id="60f535f0" class="cell code" data-execution_count="10"
data-executionInfo="{&quot;elapsed&quot;:36,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278616,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="60f535f0">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SinusoidalEmbeddings(nn.Module):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, time_steps:<span class="bu">int</span>, embed_dim: <span class="bu">int</span>):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        position <span class="op">=</span> torch.arange(time_steps).unsqueeze(<span class="dv">1</span>).<span class="bu">float</span>()</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        div <span class="op">=</span> torch.exp(torch.arange(<span class="dv">0</span>, embed_dim, <span class="dv">2</span>).<span class="bu">float</span>() <span class="op">*</span> <span class="op">-</span>(math.log(<span class="fl">10000.0</span>) <span class="op">/</span> embed_dim))</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> torch.zeros(time_steps, embed_dim, requires_grad<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        embeddings[:, <span class="dv">0</span>::<span class="dv">2</span>] <span class="op">=</span> torch.sin(position <span class="op">*</span> div)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        embeddings[:, <span class="dv">1</span>::<span class="dv">2</span>] <span class="op">=</span> torch.cos(position <span class="op">*</span> div)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embeddings <span class="op">=</span> embeddings</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, t):</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.embeddings.to(t.device)[t]</span></code></pre></div>
</div>
<div id="f0b79ae3" class="cell markdown" id="f0b79ae3">
<h3 id="unet--the-full-diffusion-model-backbone"><code>UNET</code> ‚Äî the
full diffusion model backbone</h3>
<p>Now it‚Äôs time to define the full <strong>U-Net</strong> model used in
DDPMs.<br />
This architecture combines all previously defined components ‚Äî residual,
attention, downsample, and upsample blocks ‚Äî into one encoder‚Äìdecoder
network.</p>
<hr />
<p><strong>Constructor arguments.</strong></p>
<ul>
<li><code>input_channels</code> <em>(int)</em>: number of input channels
(1 for grayscale, 3 for RGB).<br />
</li>
<li><code>time_steps</code> <em>(int)</em>: total number of diffusion
steps (for time embeddings).<br />
</li>
<li><code>base</code> <em>(int)</em>: base channel multiplier
controlling network width.<br />
</li>
<li><code>C_emb</code> <em>(int)</em>: dimension of the time
embedding.<br />
</li>
<li><code>num_groups</code> <em>(int)</em>: number of groups for
<code>GroupNorm</code>.<br />
</li>
<li><code>dropout_prob</code> <em>(float)</em>: dropout probability for
residual blocks.</li>
</ul>
<hr />
<p><strong>Architecture overview.</strong></p>
<ul>
<li><p><strong>Time embeddings:</strong><br />
Each timestep <span class="math inline"><em>t</em></span> is encoded
into a sinusoidal embedding using <code>SinusoidalEmbeddings</code>,
which conditions all <code>ResnetBlock2D</code> layers.</p></li>
<li><p><strong>Input &amp; output heads:</strong></p>
<ul>
<li><code>conv_in</code>: initial <span class="math inline">3‚ÄÖ√ó‚ÄÖ3</span>
convolution to project input to <code>base</code> channels.<br />
</li>
<li><code>norm_out</code> ‚Üí <code>SiLU</code> ‚Üí
<code>conv_out 3x3</code>: final normalization, activation, and
projection back to <code>input_channels</code>.</li>
</ul></li>
<li><p><strong>Encoder (Down path):</strong><br />
Series of <code>DownBlock2D</code>s that progressively reduce spatial
size and increase channel depth:</p>
<ul>
<li><code>down1</code>: no attention<br />
</li>
<li><code>down2</code>: includes attention<br />
</li>
<li><code>down3</code>: no attention</li>
</ul></li>
<li><p><strong>Bottleneck (Middle block):</strong><br />
<code>MidBlock2D</code> with a self-attention layer at the lowest
resolution.</p></li>
<li><p><strong>Decoder (Up path):</strong><br />
Series of <code>UpBlock2D</code>s that upsample feature maps and fuse
skip connections from the encoder:</p>
<ul>
<li><code>up1</code>: no attention<br />
</li>
<li><code>up2</code>: includes attention<br />
</li>
<li><code>up3</code>: no attention</li>
</ul></li>
</ul>
<hr />
<p><strong>Forward pass.</strong></p>
<ol>
<li>Input <code>x</code> of shape <code>(B, input_channels, H, W)</code>
is projected with <code>conv_in</code>.<br />
</li>
<li>Compute time embedding
<code>emb = SinusoidalEmbeddings(t)</code>.<br />
</li>
<li><strong>Encoder:</strong>
<ul>
<li><code>h, skip1 = down1(h, emb)</code></li>
<li><code>h, skip2 = down2(h, emb)</code></li>
<li><code>h, skip3 = down3(h, emb)</code></li>
</ul></li>
<li><strong>Bottleneck:</strong>
<ul>
<li><code>h = mid(h, emb)</code></li>
</ul></li>
<li><strong>Decoder:</strong>
<ul>
<li><code>h = up1(h, skip3, emb)</code></li>
<li><code>h = up2(h, skip2, emb)</code></li>
<li><code>h = up3(h, skip1, emb)</code></li>
</ul></li>
<li><strong>Output:</strong><br />
Normalize ‚Üí activate ‚Üí final convolution ‚Üí output prediction
<code>out</code>.</li>
</ol>
</div>
<div id="aeee9838" class="cell code" data-execution_count="11"
data-executionInfo="{&quot;elapsed&quot;:6,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156278625,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="aeee9838">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UNET(nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                 input_channels: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                 time_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>                 base: <span class="bu">int</span> <span class="op">=</span> <span class="dv">128</span>,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                 C_emb: <span class="bu">int</span> <span class="op">=</span> <span class="dv">512</span>,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                 num_groups: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>                 dropout_prob: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>):</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Time/step embeddings</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embeddings <span class="op">=</span> SinusoidalEmbeddings(time_steps<span class="op">=</span>time_steps, embed_dim<span class="op">=</span>C_emb)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Input &amp; output heads</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_in <span class="op">=</span> nn.Conv2d(input_channels, base, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm_out <span class="op">=</span> nn.GroupNorm(num_groups, base)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nonlinear <span class="op">=</span> nn.SiLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_out <span class="op">=</span> nn.Conv2d(base, input_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Encoder (down path) ----------</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down1 <span class="op">=</span> DownBlock2D(</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>            C_in<span class="op">=</span>base, C_out<span class="op">=</span>base, C_emb<span class="op">=</span>C_emb,</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>            num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_prob, use_attn<span class="op">=</span><span class="va">False</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down2 <span class="op">=</span> DownBlock2D(</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>            C_in<span class="op">=</span>base, C_out<span class="op">=</span>base <span class="op">*</span> <span class="dv">2</span>, C_emb<span class="op">=</span>C_emb,</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>            num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_prob, use_attn<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down3 <span class="op">=</span> DownBlock2D(</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>            C_in<span class="op">=</span>base <span class="op">*</span> <span class="dv">2</span>, C_out<span class="op">=</span>base <span class="op">*</span> <span class="dv">4</span>, C_emb<span class="op">=</span>C_emb,</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>            num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_prob, use_attn<span class="op">=</span><span class="va">False</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Middle bottleneck ----------</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mid <span class="op">=</span> MidBlock2D(</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>            C<span class="op">=</span>base <span class="op">*</span> <span class="dv">4</span>, C_emb<span class="op">=</span>C_emb,</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>            num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_prob</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Decoder (up path) ----------</span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up1 <span class="op">=</span> UpBlock2D(</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>            C_in<span class="op">=</span>base <span class="op">*</span> <span class="dv">4</span>, C_skip<span class="op">=</span>base <span class="op">*</span> <span class="dv">4</span>, C_out<span class="op">=</span>base <span class="op">*</span> <span class="dv">2</span>, C_emb<span class="op">=</span>C_emb,</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>            num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_prob, use_attn<span class="op">=</span><span class="va">False</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up2 <span class="op">=</span> UpBlock2D(</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>            C_in<span class="op">=</span>base <span class="op">*</span> <span class="dv">2</span>, C_skip<span class="op">=</span>base <span class="op">*</span> <span class="dv">2</span>, C_out<span class="op">=</span>base, C_emb<span class="op">=</span>C_emb,</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>            num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_prob, use_attn<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up3 <span class="op">=</span> UpBlock2D(</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>            C_in<span class="op">=</span>base, C_skip<span class="op">=</span>base, C_out<span class="op">=</span>base, C_emb<span class="op">=</span>C_emb,</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>            num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_prob, use_attn<span class="op">=</span><span class="va">False</span></span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a><span class="co">        x: (B, input_channels, H, W)</span></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a><span class="co">        t: (B,) integer timesteps compatible with SinusoidalEmbeddings</span></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>        B, _, H, W <span class="op">=</span> x.shape</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.conv_in(x)</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> <span class="va">self</span>.embeddings(t).to(h.device)</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Down path (encoder) ----------</span></span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>        h, skip1 <span class="op">=</span> <span class="va">self</span>.down1(h, emb)   <span class="co"># (B, base, H/2, W/2)</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>        h, skip2 <span class="op">=</span> <span class="va">self</span>.down2(h, emb)   <span class="co"># (B, 2*base, H/4, W/4)</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>        h, skip3 <span class="op">=</span> <span class="va">self</span>.down3(h, emb)   <span class="co"># (B, 4*base, H/8, W/8)</span></span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Bottleneck ----------</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.mid(h, emb)</span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Up path (decoder) ----------</span></span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.up1(h, skip3, emb)     <span class="co"># (B, 2*base, H/4, W/4)</span></span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.up2(h, skip2, emb)     <span class="co"># (B, base, H/2, W/2)</span></span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.up3(h, skip1, emb)     <span class="co"># (B, base, H, W)</span></span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Output ----------</span></span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.norm_out(h)</span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.nonlinear(h)</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.conv_out(h)</span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code></pre></div>
</div>
<div id="21f05596" class="cell markdown" id="21f05596">
<p>Quick check if we have same output shape as input.</p>
</div>
<div id="e59cb316" class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-executionInfo="{&quot;elapsed&quot;:5307,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156283937,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="e59cb316" data-outputId="164c5281-4913-4ac1-9595-0da5f4456db6">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> UNET()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand((<span class="dv">16</span>, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.randint(<span class="dv">0</span>,<span class="dv">1000</span>,(<span class="dv">16</span>,))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>model(x, t).shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="12">
<pre><code>torch.Size([16, 1, 28, 28])</code></pre>
</div>
</div>
<div id="33170383" class="cell markdown" id="&quot;33170383&quot;">
<h3
id="diffusionmodel--training-and-sampling-with-pytorch-lightning"><code>DiffusionModel</code>
‚Äî training and sampling with PyTorch Lightning</h3>
<p>The final step is wrapping our U-Net and scheduler into a complete
<strong>training module</strong>.<br />
The <code>DiffusionModel</code> class manages training, optimization,
and sample generation using the PyTorch Lightning framework.</p>
<p><strong>Main components.</strong></p>
<ul>
<li><code>UNET</code>: the denoising backbone predicting the added noise
at each timestep.<br />
</li>
<li><code>DDPM_Scheduler</code>: precomputes <span
class="math inline"><em>Œ≤</em><sub><em>t</em></sub></span> and <span
class="math inline"><em>Œ±</em><sub><em>t</em></sub></span> schedules for
noise addition.<br />
</li>
<li><code>MSELoss</code>: the DDPM training objective ‚Äî model predicts
the noise added to each image.<br />
</li>
<li>Fixed noise buffers (<code>fixed_noise</code>,
<code>fixed_noise_seq</code>) for deterministic sampling and
logging.</li>
</ul>
<h3 id="training-step"><strong>Training step</strong></h3>
<p>The model learns to predict the noise <span
class="math inline"><em>Œµ</em></span> added during the forward diffusion
process. This directly implements the simplified DDPM loss from Ho
<em>et al.</em>, 2020.</p>
<p><strong>Algorithm:</strong></p>
<ol>
<li>Sample a batch of clean images <code>x</code> from the
dataset.<br />
</li>
<li>Randomly pick diffusion timesteps <code>t ‚àà [0, T)</code>.<br />
</li>
<li>Sample random Gaussian noise <span class="math inline">$`\varepsilon
‚àº N(0, I)`$</span>.<br />
</li>
<li>Generate noisy images using: <span class="math display">$$
x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \,
\varepsilon
$$</span></li>
<li>Feed the noisy image and timestep to the model: <span
class="math display"><em>ŒµÃÇ</em><sub><em>Œ∏</em></sub>‚ÄÑ=‚ÄÑmodel(<em>x</em><sub><em>t</em></sub>,<em>t</em>)</span></li>
<li>Compute the MSE loss: <span
class="math display">‚Ñí‚ÄÑ=‚ÄÑ‚à•<em>Œµ</em>‚ÄÖ‚àí‚ÄÖ<em>ŒµÃÇ</em><sub><em>Œ∏</em></sub>‚à•<sup>2</sup></span></li>
<li>Log training metrics (<code>train_loss</code>) for monitoring.</li>
</ol>
<h3 id="sampling-image-generation"><strong>Sampling (image
generation)</strong></h3>
<p>The <code>generate_samples</code> method runs the <strong>reverse
diffusion process</strong>, turning pure noise into images.</p>
<p><strong>Algorithm:</strong></p>
<ol>
<li>Start with Gaussian noise <code>z_T ‚àº N(0, I)</code>.<br />
</li>
<li>Iterate backward over timesteps <code>t = T ‚Ä¶ 1</code>:
<ul>
<li>Predict the noise <span
class="math inline"><em>ŒµÃÇ</em><sub><em>Œ∏</em></sub>‚ÄÑ=‚ÄÑmodel(<em>z</em><sub><em>t</em></sub>,<em>t</em>)</span><br />
</li>
<li>Estimate the denoised image: <span class="math display">$$
z_{t-1} = \frac{1}{\sqrt{\alpha_t}} \Big(z_t - \frac{1 -
\alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \, \hat{\varepsilon}_\theta \Big) +
\sqrt{\beta_t} \, \varepsilon_t
$$</span> where <span
class="math inline"><em>Œµ</em><sub><em>t</em></sub></span> is Gaussian
noise (set to zero for deterministic sampling).</li>
</ul></li>
<li>Return final output <code>z_0</code> (the generated image).<br />
</li>
<li>Clamp pixel values to <code>[0, 1]</code> for valid image
ranges.</li>
</ol>
<p><strong>Modes:</strong></p>
<ul>
<li><code>deterministic=True</code>: use fixed stored noise
(reproducible samples).<br />
</li>
<li><code>deterministic=False</code>: randomize for diversity.</li>
</ul>
<p><img src = "https://raw.githubusercontent.com/vision-agh/DNN-Course-media/refs/heads/main/lab8_diffusion/figures/algorithms.png" alt="Algorithms" width="600"></p>
</div>
<div id="9eaa3abd" class="cell code" data-execution_count="13"
data-executionInfo="{&quot;elapsed&quot;:6,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1762156283972,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="9eaa3abd">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DiffusionModel(L.LightningModule):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                 in_channels: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>                 img_shape: Tuple <span class="op">=</span> (<span class="dv">28</span>, <span class="dv">28</span>),</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>                 num_time_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>                 lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">2e-5</span>):</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.save_hyperparameters()</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_channels <span class="op">=</span> in_channels</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_time_steps <span class="op">=</span> num_time_steps</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_shape <span class="op">=</span> img_shape</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> UNET(input_channels<span class="op">=</span>in_channels, time_steps<span class="op">=</span>num_time_steps)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scheduler <span class="op">=</span> DDPM_Scheduler(num_time_steps<span class="op">=</span>num_time_steps)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion <span class="op">=</span> nn.MSELoss(reduction<span class="op">=</span><span class="st">&#39;mean&#39;</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">&quot;fixed_noise&quot;</span>, torch.randn(<span class="dv">16</span>, in_channels, <span class="op">*</span>img_shape))</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">&quot;fixed_noise_seq&quot;</span>, torch.randn(num_time_steps, <span class="dv">16</span>, in_channels, <span class="op">*</span>img_shape))</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> training_step(<span class="va">self</span>, batch, batch_idx):</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> batch</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        B <span class="op">=</span> x.size(<span class="dv">0</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="va">self</span>.num_time_steps, (B,), device<span class="op">=</span><span class="va">self</span>.device)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        e <span class="op">=</span> torch.randn_like(x)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> <span class="va">self</span>.scheduler.alpha.to(<span class="va">self</span>.device)[t].view(B, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>        x_noisy <span class="op">=</span> (torch.sqrt(a) <span class="op">*</span> x) <span class="op">+</span> (torch.sqrt(<span class="dv">1</span> <span class="op">-</span> a) <span class="op">*</span> e)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.model(x_noisy, t)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="va">self</span>.criterion(output, e)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log(<span class="st">&quot;train_loss&quot;</span>, loss, prog_bar<span class="op">=</span><span class="va">True</span>, on_step<span class="op">=</span><span class="va">True</span>, on_epoch<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> configure_optimizers(<span class="va">self</span>):</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.AdamW(</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model.parameters(),</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>            lr<span class="op">=</span><span class="va">self</span>.lr,</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>            weight_decay<span class="op">=</span><span class="fl">1e-4</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cosine annealing scheduler (smoothly decreases LR during training)</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>        scheduler <span class="op">=</span> torch.optim.lr_scheduler.CosineAnnealingLR(</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>            optimizer,</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>            T_max<span class="op">=</span><span class="va">self</span>.trainer.max_epochs,</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>            eta_min<span class="op">=</span><span class="va">self</span>.lr <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;optimizer&quot;</span>: optimizer,</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;lr_scheduler&quot;</span>: {</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;scheduler&quot;</span>: scheduler,</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;interval&quot;</span>: <span class="st">&quot;epoch&quot;</span>,</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;frequency&quot;</span>: <span class="dv">1</span>,</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>    <span class="at">@torch.no_grad</span>()</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_samples(<span class="va">self</span>, n_samples<span class="op">=</span><span class="dv">16</span>, num_time_steps<span class="op">=</span><span class="dv">1000</span>, deterministic<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.<span class="bu">eval</span>()</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Start from random noise</span></span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> deterministic:</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> <span class="va">self</span>.fixed_noise.clone().to(<span class="va">self</span>.device)</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> torch.randn(n_samples, <span class="va">self</span>.in_channels, <span class="op">*</span><span class="va">self</span>.img_shape).to(<span class="va">self</span>.device)</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>        scheduler <span class="op">=</span> <span class="va">self</span>.scheduler</span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="dv">1</span>, num_time_steps)):</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a>            t_tensor <span class="op">=</span> torch.tensor([t], device<span class="op">=</span>z.device).repeat(n_samples)</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>            beta_t <span class="op">=</span> scheduler.beta.to(<span class="va">self</span>.device)[t_tensor].view(n_samples, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> beta_t</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>            hat_alpha_t <span class="op">=</span> scheduler.alpha.to(<span class="va">self</span>.device)[t_tensor].view(n_samples, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Predict noise using the model</span></span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a>            predicted_noise <span class="op">=</span> <span class="va">self</span>.model(z, t_tensor)</span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute the mean term</span></span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> (<span class="fl">1.0</span> <span class="op">/</span> torch.sqrt(alpha_t)) <span class="op">*</span> (</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>                z <span class="op">-</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_t) <span class="op">/</span> torch.sqrt(<span class="dv">1</span> <span class="op">-</span> hat_alpha_t)) <span class="op">*</span> predicted_noise</span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add noise if not the first step</span></span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> t <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> deterministic:</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a>                    e <span class="op">=</span> <span class="va">self</span>.fixed_noise_seq[t].clone().to(<span class="va">self</span>.device)</span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>                    e <span class="op">=</span> torch.randn_like(z)</span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> z <span class="op">+</span> torch.sqrt(beta_t) <span class="op">*</span> e</span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> z.clamp(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_train_epoch_end(<span class="va">self</span>):</span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Log generated samples to W&amp;B every few epochs&quot;&quot;&quot;</span></span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a>        imgs <span class="op">=</span> <span class="va">self</span>.generate_samples(n_samples<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a>        grid <span class="op">=</span> make_grid(imgs, nrow<span class="op">=</span><span class="dv">4</span>, normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.logger.experiment.log({</span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;generated_samples&quot;</span>: [wandb.Image(grid, caption<span class="op">=</span><span class="ss">f&quot;Epoch </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>current_epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&quot;</span>)]</span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a>        })</span></code></pre></div>
</div>
<div id="cdd403ed" class="cell markdown" id="cdd403ed">
<p>We will train our model on MNIST dataset, we will use only Training
split.</p>
<p>We initialize WandbLogger from Pytorch Lightning, our DiffusionModel,
checkpoint for saving weights based on training loss and we can start
training.</p>
<p><strong>Important!</strong></p>
<p>You can train model for 10/25 epochs to reduce time and check if it
works and then load pretrained weights from here <a
href="https://drive.google.com/drive/folders/1kGQhn7gRQ2YvKLYduWGArTfTBk20JR-J?usp=sharing">link</a>.</p>
</div>
<div id="bd2cda2f" class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;b64ca484d5a5464ba8beb1e9737d7270&quot;,&quot;9a07e1ef6eee4a53bef2df5d7caa5a34&quot;,&quot;6e04f77cc9774acb9e218bcfabba81df&quot;,&quot;68f2cb4a84f646e7ac60929c54927c0f&quot;,&quot;2ced706d69e64c56870a4843029e0f3f&quot;,&quot;da3ba7e615324ef7884f0d11464f3daf&quot;,&quot;dc1a1aedbcac4052be0bc9ebd46c5660&quot;,&quot;c3b3867876f24f01af08a174221329f6&quot;,&quot;0ee467bbf0cc4d77bbbffadf1069113e&quot;,&quot;5331b92533e04f7c96ace15165d7a3ed&quot;,&quot;9fa3d426fa5f4cbeaa7040b7ab5912d5&quot;]}"
data-executionInfo="{&quot;elapsed&quot;:2270998,&quot;status&quot;:&quot;error&quot;,&quot;timestamp&quot;:1762158554977,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="bd2cda2f" data-outputId="6ba516b1-de51-4f09-8c2e-12f0548d7c4a">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>num_workers <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>num_time_steps <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">2e-5</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">&quot;./data&quot;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span>num_workers, drop_last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># W&amp;B logger</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>wandb_logger <span class="op">=</span> WandbLogger(project<span class="op">=</span><span class="st">&quot;lab8-diffusion&quot;</span>,</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>                           entity<span class="op">=</span><span class="st">&quot;deep-neural-network-course&quot;</span>,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>                           group<span class="op">=</span><span class="st">&quot;diffusion-model&quot;</span>,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>                           name<span class="op">=</span> <span class="st">&quot;Jan Rosa&quot;</span>,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>                           log_model<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Model + Trainer setup</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DiffusionModel(num_time_steps<span class="op">=</span>num_time_steps, lr<span class="op">=</span>lr)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>checkpoint_callback <span class="op">=</span> ModelCheckpoint(</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        dirpath<span class="op">=</span><span class="st">&quot;./checkpoints&quot;</span>,</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        filename<span class="op">=</span><span class="st">&quot;diffusion-</span><span class="sc">{epoch:02d}</span><span class="st">-</span><span class="sc">{train_loss:.4f}</span><span class="st">&quot;</span>,</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>        save_top_k<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        monitor<span class="op">=</span><span class="st">&quot;train_loss&quot;</span>,</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>        mode<span class="op">=</span><span class="st">&quot;min&quot;</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> L.Trainer(</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>    max_epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    precision<span class="op">=</span><span class="st">&quot;16-mixed&quot;</span>,</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    logger<span class="op">=</span>wandb_logger,</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[checkpoint_callback],</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    log_every_n_steps<span class="op">=</span><span class="dv">50</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a><span class="co"># trainer.fit(model, train_loader)</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a><span class="co"># wandb.finish()</span></span></code></pre></div>
<div class="output stream stderr">
<pre><code>/home/jrosa/AGH_FILES/GSN-2025W/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:508: You passed `Trainer(accelerator=&#39;cpu&#39;, precision=&#39;16-mixed&#39;)` but AMP with fp16 is not supported on CPU. Using `precision=&#39;bf16-mixed&#39;` instead.
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
</code></pre>
</div>
</div>
<div id="50b19017" class="cell markdown" id="50b19017">
<p>Generate examples from pretrained model.</p>
</div>
<div id="77329dbc" class="cell code" data-execution_count="15"
data-executionInfo="{&quot;elapsed&quot;:2281149,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554968,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="77329dbc">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DiffusionModel.load_from_checkpoint(<span class="st">&#39;checkpoints/diffusion-epoch=44-train_loss=0.0138.ckpt&#39;</span>, map_location<span class="op">=</span>device)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> model.generate_samples(deterministic<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> make_grid(out, nrow<span class="op">=</span><span class="dv">4</span>, normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> grid.cpu().permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).numpy()</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(grid)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="9b66b7650d2ed559f90e53d16925c826377d6f83.png" /></p>
</div>
</div>
<div id="4e187634" class="cell markdown" id="4e187634">
<p>And also we can visualise process of denoising sample:</p>
</div>
<div id="a2011e48" class="cell code" data-execution_count="16"
data-executionInfo="{&quot;elapsed&quot;:2281148,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554969,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="a2011e48">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_reverse(images: List[torch.Tensor]):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="bu">len</span>(images), figsize<span class="op">=</span>(<span class="bu">len</span>(images), <span class="dv">1</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes.flat):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> images[i].squeeze(<span class="dv">0</span>).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).cpu().numpy()</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        ax.imshow(x, cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> inference(checkpoint: <span class="bu">str</span>, num_time_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>):</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> DiffusionModel.load_from_checkpoint(checkpoint, map_location<span class="op">=</span>device)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> DDPM_Scheduler(num_time_steps<span class="op">=</span>num_time_steps)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    times <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">15</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">400</span>, <span class="dv">550</span>, <span class="dv">700</span>, <span class="dv">999</span>]</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> []</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> model.<span class="bu">eval</span>()</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>).to(device)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="dv">1</span>, num_time_steps)):</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>            t_tensor <span class="op">=</span> torch.tensor([t], device<span class="op">=</span>x.device).repeat(<span class="dv">1</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>            beta_t <span class="op">=</span> scheduler.beta.to(device)[t_tensor].view(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> scheduler.alpha.to(device)[t_tensor].view(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>            temp <span class="op">=</span> beta_t <span class="op">/</span> (torch.sqrt(<span class="dv">1</span> <span class="op">-</span> alpha_t) <span class="op">*</span> torch.sqrt(<span class="dv">1</span> <span class="op">-</span> beta_t))</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> torch.sqrt(<span class="dv">1</span> <span class="op">-</span> beta_t)) <span class="op">*</span> x <span class="op">-</span> (temp <span class="op">*</span> model.model(x, t_tensor))</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>            e <span class="op">=</span> torch.randn_like(x)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x <span class="op">+</span> e <span class="op">*</span> torch.sqrt(beta_t)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> t <span class="kw">in</span> times:</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>                images.append(x.clone().detach().cpu())</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    final_img <span class="op">=</span> x.squeeze(<span class="dv">0</span>).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).detach().cpu().numpy()</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    plt.imshow(final_img, cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&quot;Final generated image&quot;</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    display_reverse(<span class="bu">list</span>(images))</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>inference(<span class="st">&quot;checkpoints/diffusion-epoch=44-train_loss=0.0138.ckpt&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img src="1141fbf9706d5fedf51723a2ee1a54947c1745cb.png" /></p>
</div>
<div class="output display_data">
<p><img src="1b13ec48469d6e6c47ddd3a03847813ada8424cd.png" /></p>
</div>
</div>
<div id="cde967e4" class="cell markdown" id="cde967e4">
<h3
id="conditional-diffusion-model--adding-control-to-generation">Conditional
Diffusion Model ‚Äî adding control to generation</h3>
<p>If everything has been implemented correctly, we should now be able
to generate <strong>clear images of digits</strong> üéâ<br />
That completes our <strong>basic Diffusion Model</strong>!</p>
<hr />
<h3 id="why-conditional-diffusion">Why conditional diffusion?</h3>
<p>In our current setup, sampling starts from <strong>pure
noise</strong> ‚Äî so each generated image is <strong>completely
random</strong>.<br />
We have no control over what kind of image appears at the output.</p>
<p>To fix this, we can introduce <strong>conditioning
information</strong>, such as a class label or a text embedding, that
guides the denoising process toward a specific type of output.<br />
For example:</p>
<ul>
<li>Generating a <strong>digit ‚Äú7‚Äù</strong> in MNIST, or<br />
</li>
<li>Creating a <strong>cat</strong> image instead of a
<strong>dog</strong>, or<br />
</li>
<li>Using a <strong>text prompt</strong> like <em>‚Äúa sunset over the
mountains‚Äù</em> in <strong>Stable Diffusion</strong>.</li>
</ul>
<p>This approach is called a <strong>Conditional Diffusion
Model</strong> ‚Äî the model learns to condition its generation on an
additional input (class, text, or latent embedding).</p>
<hr />
<h3 id="real-world-example-stable-diffusion">Real-world example: Stable
Diffusion</h3>
<p>Let‚Äôs look at how this concept scales to larger, real-world
text-to-image models such as <a
href="https://stablediffusionweb.com/"><strong>Stable
Diffusion</strong></a>.</p>
<p>Even though implementations differ, most modern conditional diffusion
systems share <strong>three core components</strong>:</p>
<ol>
<li><strong>Text Encoder</strong> ‚Äî transforms text into embeddings that
condition image generation.
<ul>
<li>Example: <a
href="https://github.com/openai/CLIP"><strong>CLIP</strong></a> from
OpenAI, which aligns text and image embeddings using Transformer
encoders.<br />
</li>
<li>The output embedding serves as a <em>conditioning vector</em> for
the diffusion model.</li>
</ul></li>
<li><strong>U-Net Denoising Model</strong> ‚Äî performs iterative
denoising in latent space.
<ul>
<li>This is essentially our <strong>U-Net</strong>, but often extended
with <strong>cross-attention layers</strong> to incorporate conditioning
information (e.g., from text).</li>
</ul></li>
<li><strong>Variational Autoencoder (VAE)</strong> ‚Äî encodes
high-resolution images into a smaller <strong>latent space</strong>,
reducing memory and computation.
<ul>
<li>The diffusion process operates in this compressed latent
space.<br />
</li>
<li>The final decoded result is obtained by running the <strong>VAE
decoder</strong>.</li>
</ul></li>
</ol>
<p>These three parts together allow for <strong>efficient</strong>,
<strong>high-resolution</strong>, and <strong>text-controlled</strong>
generation.</p>
<hr />
<h3 id="our-simplified-conditional-model">Our simplified conditional
model</h3>
<p>Since training a full-scale Stable Diffusion model is
resource-intensive, we can instead <strong>adapt our current diffusion
model</strong> to accept conditioning signals.<br />
We‚Äôll focus on adding <strong>Cross-Attention</strong> layers ‚Äî a
mechanism that lets the model <em>attend</em> to an external embedding
(e.g. class label or text feature).</p>
<hr />
<h3
id="crossattentionblock--fusing-conditioning-information"><code>CrossAttentionBlock</code>
‚Äî fusing conditioning information</h3>
<p>This block works similarly to our standard
<code>AttentionBlock</code>, but with a few key modifications:</p>
<ol>
<li>We now have <strong>separate channel dimensions</strong> for queries
(<code>C_q</code>) and for keys/values (<code>C_kv</code>).<br />
</li>
<li>The <code>key</code> and <code>value</code> linear layers map from
<code>C_kv ‚Üí C_q</code>, while <code>query</code> maps from
<code>C_q ‚Üí C_q</code>.<br />
</li>
<li>We <strong>do not</strong> use normalization here.<br />
</li>
<li>We <strong>flatten only the query input</strong> (<code>x_q</code>),
while the conditioning input (<code>x_kv</code>) is already in the
correct shape.<br />
</li>
<li>Each of the query, key, and value tensors is projected through its
corresponding <code>Linear</code> layer.<br />
</li>
<li>We reshape them for multi-head attention based on their respective
sequence lengths <code>L_q</code> and <code>L_ctx</code>.<br />
</li>
<li>We apply <code>F.scaled_dot_product_attention</code>, just as
before, followed by recombining the heads and a final linear
projection.</li>
</ol>
</div>
<div id="98cc5dbc" class="cell code" data-execution_count="17"
data-executionInfo="{&quot;elapsed&quot;:2281147,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554971,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="98cc5dbc">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossAttentionBlock(nn.Module):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, C_q: <span class="bu">int</span>, C_kv: <span class="bu">int</span>, num_heads: <span class="bu">int</span>, dropout_p: <span class="bu">float</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> C_q <span class="op">%</span> num_heads <span class="op">==</span> <span class="dv">0</span>, <span class="st">&quot;C_q must be divisible by num_heads&quot;</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head_dim <span class="op">=</span> C_q <span class="op">//</span> num_heads</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout_p <span class="op">=</span> dropout_p</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Linear projections for query (from image) and key/value (from embeddings)</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.query <span class="op">=</span> nn.Linear(C_q, C_q)  <span class="co"># C_q -&gt; C_q</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.key <span class="op">=</span> nn.Linear(C_kv, C_q)    <span class="co"># C_kv -&gt; C_q  </span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> nn.Linear(C_kv, C_q)  <span class="co"># C_kv -&gt; C_q</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj_out <span class="op">=</span> nn.Linear(C_q, C_q)  <span class="co"># C_q -&gt; C_q</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x_q, x_kv):</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="co">            x_q: (B, C_q, H, W) - query feature map</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="co">            x_kv: (B, L_ctx, C_kv) - contextual embeddings</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="co">            out: (B, C_q, H, W)</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        B, Cq, H, W <span class="op">=</span> x_q.shape</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        B, L_ctx, Ckv <span class="op">=</span> x_kv.shape</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Flatten spatial dims of query</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        q_flat <span class="op">=</span> x_q.view(B, Cq, H <span class="op">*</span> W).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)  <span class="co"># (B, L_q, C_q) where L_q = H*W</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        L_q <span class="op">=</span> q_flat.shape[<span class="dv">1</span>]</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Linear projections for query, key, and value</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.query(q_flat)  <span class="co"># (B, L_q, C_q)</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.key(x_kv)      <span class="co"># (B, L_ctx, C_q)</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.value(x_kv)    <span class="co"># (B, L_ctx, C_q)</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape for multi-head attention</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> q.view(B, L_q, <span class="va">self</span>.num_heads, <span class="va">self</span>.head_dim).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>)  <span class="co"># (B, H, L_q, d)</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> k.view(B, L_ctx, <span class="va">self</span>.num_heads, <span class="va">self</span>.head_dim).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>)  <span class="co"># (B, H, L_ctx, d)</span></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.view(B, L_ctx, <span class="va">self</span>.num_heads, <span class="va">self</span>.head_dim).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>)  <span class="co"># (B, H, L_ctx, d)</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute scaled dot-product attention</span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>        attn_weights <span class="op">=</span> torch.matmul(q, k.transpose(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>)) <span class="op">*</span> (<span class="va">self</span>.head_dim <span class="op">**</span> <span class="op">-</span><span class="fl">0.5</span>)  <span class="co"># (B, H, L_q, L_ctx)</span></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>        attn_weights <span class="op">=</span> F.softmax(attn_weights, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.dropout_p <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>            attn_weights <span class="op">=</span> F.dropout(attn_weights, p<span class="op">=</span><span class="va">self</span>.dropout_p, training<span class="op">=</span><span class="va">self</span>.training)</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply attention to values</span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.matmul(attn_weights, v)  <span class="co"># (B, H, L_q, d)</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine heads and reshape back</span></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>).contiguous().view(B, L_q, Cq)  <span class="co"># (B, L_q, C_q)</span></span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.proj_out(out)  <span class="co"># (B, L_q, C_q)</span></span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape back to image dimensions</span></span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>).view(B, Cq, H, W)  <span class="co"># (B, C_q, H, W)</span></span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code></pre></div>
</div>
<div id="c0744e89" class="cell markdown" id="c0744e89">
<p>We introduce this inside MidBlock2D, right after AttentionBlock.</p>
<p>Define <code>CrossMidBlock2D</code> with additional
<code>CrossAttentionBlock</code> with parameter <code>C_cls</code>. In
forward use it after <code>self.attn</code> and remember to use
<code>emb.cls.unsqueeze(1)</code>. Output of this Cross Attention goes
to second ResNetBlock.</p>
</div>
<div id="0c5ba963" class="cell code" data-execution_count="18"
data-executionInfo="{&quot;elapsed&quot;:2281145,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554972,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="0c5ba963">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossMidBlock2D(nn.Module):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, C, C_emb, C_cls, num_groups, dropout_p):</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res1 <span class="op">=</span> ResnetBlock2D(C, C, C_emb, num_groups, dropout_p)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> AttentionBlock(C, num_heads<span class="op">=</span><span class="dv">8</span>, num_groups<span class="op">=</span>num_groups, dropout_p<span class="op">=</span>dropout_p)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cross_attn <span class="op">=</span> CrossAttentionBlock(C, C_cls, num_heads<span class="op">=</span><span class="dv">8</span>, dropout_p<span class="op">=</span>dropout_p)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res2 <span class="op">=</span> ResnetBlock2D(C, C, C_emb, num_groups, dropout_p)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb, emb_cls):</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res1(x, emb)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attn(x)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use cross attention with class embeddings</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.cross_attn(x, emb_cls.unsqueeze(<span class="dv">1</span>))  <span class="co"># Add residual connection</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.res2(x, emb)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div id="a2acd10f" class="cell markdown" id="a2acd10f">
<p>We now define our <code>ConditionalUNET</code>, which inherits from
the <code>UNET</code> class.<br />
In the <code>__init__</code> method, we replace the <code>mid</code>
layer with our new <code>CrossMidBlock2D</code> <strong>(cls and time
embeddings size are equal to <code>C_emb</code>)</strong>, and
additionally define an <code>nn.Embedding</code> layer with 10 classes
(since we are using the MNIST dataset) that maps class labels to the
same embedding dimension <code>C_emb</code>.</p>
<p>In the <code>forward</code> method, we add:</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>emb_cls <span class="op">=</span> <span class="va">self</span>.cls_embeddings(cls.to(x.device))</span></code></pre></div>
<p>and modify the bottleneck call to:</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="va">self</span>.mid(h, emb, emb_cls)</span></code></pre></div>
</div>
<div id="09ca15e7" class="cell code" data-execution_count="19"
data-executionInfo="{&quot;elapsed&quot;:2281144,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554973,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="09ca15e7">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConditionalUNET(UNET):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>                 input_channels: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>                 time_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>                 base: <span class="bu">int</span> <span class="op">=</span> <span class="dv">128</span>,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                 C_emb <span class="op">=</span> <span class="dv">512</span>,</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                 num_groups: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span>,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>                 dropout_prob: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>):</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(input_channels<span class="op">=</span>input_channels,</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>                 time_steps<span class="op">=</span>time_steps,</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>                 base<span class="op">=</span>base,</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>                 C_emb <span class="op">=</span> C_emb,</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>                 num_groups<span class="op">=</span>num_groups,</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>                 dropout_prob<span class="op">=</span>dropout_prob)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cls/step embeddings</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cls_embeddings <span class="op">=</span> nn.Embedding(<span class="dv">10</span>, C_emb)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mid <span class="op">=</span> CrossMidBlock2D(base <span class="op">*</span> <span class="dv">4</span>, C_emb, C_emb, num_groups, dropout_prob)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, t, cls):</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="co">        x: (B, input_channels, H, W)</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co">        t: (B,) integer timesteps compatible with SinusoidalEmbeddings</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>        B, _, H, W <span class="op">=</span> x.shape</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.conv_in(x)</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> <span class="va">self</span>.embeddings(t).to(h.device)</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>        emb_cls <span class="op">=</span> <span class="va">self</span>.cls_embeddings(cls.to(x.device))</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Down path (encoder) ----------</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>        h, skip1 <span class="op">=</span> <span class="va">self</span>.down1(h, emb)   <span class="co"># (B, base, H/2, W/2)</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>        h, skip2 <span class="op">=</span> <span class="va">self</span>.down2(h, emb)   <span class="co"># (B, 2*base, H/4, W/4)</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>        h, skip3 <span class="op">=</span> <span class="va">self</span>.down3(h, emb)   <span class="co"># (B, 4*base, H/8, W/8)</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Bottleneck ----------</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.mid(h, emb, emb_cls)</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Up path (decoder) ----------</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.up1(h, skip3, emb)     <span class="co"># (B, 2*base, H/4, W/4)</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.up2(h, skip2, emb)     <span class="co"># (B, base, H/2, W/2)</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.up3(h, skip1, emb)     <span class="co"># (B, base, H, W)</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------- Output ----------</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.norm_out(h)</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.nonlinear(h)</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.conv_out(h)</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code></pre></div>
</div>
<div id="19c25b56" class="cell markdown" id="19c25b56">
<p>And also we define the <code>ConditionalDiffusionModel</code> which
simply use <code>y</code> values from MNIST dataset or arrange in
sampling method inside model as additional parameter.</p>
</div>
<div id="ee42a7ff" class="cell code" data-execution_count="20"
data-executionInfo="{&quot;elapsed&quot;:2281143,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554974,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="ee42a7ff">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConditionalDiffusionModel(L.LightningModule):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                 in_channels: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                 img_shape: Tuple <span class="op">=</span> (<span class="dv">28</span>, <span class="dv">28</span>),</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                 num_time_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>                 lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">2e-5</span>):</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.save_hyperparameters()</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_channels <span class="op">=</span> in_channels</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_time_steps <span class="op">=</span> num_time_steps</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_shape <span class="op">=</span> img_shape</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> ConditionalUNET(input_channels<span class="op">=</span>in_channels, time_steps<span class="op">=</span>num_time_steps)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scheduler <span class="op">=</span> DDPM_Scheduler(num_time_steps<span class="op">=</span>num_time_steps)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion <span class="op">=</span> nn.MSELoss(reduction<span class="op">=</span><span class="st">&#39;mean&#39;</span>)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">&quot;fixed_noise&quot;</span>, torch.randn(<span class="dv">16</span>, in_channels, <span class="op">*</span>img_shape))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">&quot;fixed_noise_seq&quot;</span>, torch.randn(num_time_steps, <span class="dv">16</span>, in_channels, <span class="op">*</span>img_shape))</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> training_step(<span class="va">self</span>, batch, batch_idx):</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> batch</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        B <span class="op">=</span> x.size(<span class="dv">0</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="va">self</span>.num_time_steps, (B,), device<span class="op">=</span><span class="va">self</span>.device)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>        e <span class="op">=</span> torch.randn_like(x)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> <span class="va">self</span>.scheduler.alpha.to(<span class="va">self</span>.device)[t].view(B, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        x_noisy <span class="op">=</span> (torch.sqrt(a) <span class="op">*</span> x) <span class="op">+</span> (torch.sqrt(<span class="dv">1</span> <span class="op">-</span> a) <span class="op">*</span> e)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.model(x_noisy, t, y)</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="va">self</span>.criterion(output, e)</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log(<span class="st">&quot;train_loss&quot;</span>, loss, prog_bar<span class="op">=</span><span class="va">True</span>, on_step<span class="op">=</span><span class="va">True</span>, on_epoch<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> configure_optimizers(<span class="va">self</span>):</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.AdamW(</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model.parameters(),</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>            lr<span class="op">=</span><span class="va">self</span>.lr,</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>            weight_decay<span class="op">=</span><span class="fl">1e-4</span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>        scheduler <span class="op">=</span> torch.optim.lr_scheduler.CosineAnnealingLR(</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>            optimizer,</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>            T_max<span class="op">=</span><span class="va">self</span>.trainer.max_epochs,</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>            eta_min<span class="op">=</span><span class="va">self</span>.lr <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;optimizer&quot;</span>: optimizer,</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;lr_scheduler&quot;</span>: {</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;scheduler&quot;</span>: scheduler,</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;interval&quot;</span>: <span class="st">&quot;epoch&quot;</span>,</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;frequency&quot;</span>: <span class="dv">1</span>,</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>    <span class="at">@torch.no_grad</span>()</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_samples(<span class="va">self</span>, n_samples<span class="op">=</span><span class="dv">16</span>, num_time_steps<span class="op">=</span><span class="dv">1000</span>, deterministic<span class="op">=</span><span class="va">True</span>, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.<span class="bu">eval</span>()</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> deterministic:</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> <span class="va">self</span>.fixed_noise.clone().to(<span class="va">self</span>.device)</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> torch.randn(n_samples, <span class="va">self</span>.in_channels, <span class="op">*</span><span class="va">self</span>.img_shape).to(<span class="va">self</span>.device)</span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>        scheduler <span class="op">=</span> <span class="va">self</span>.scheduler</span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> y <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> torch.arange(n_samples, device<span class="op">=</span><span class="va">self</span>.device) <span class="op">%</span> <span class="dv">10</span></span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="dv">1</span>, num_time_steps)):</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a>            t_tensor <span class="op">=</span> torch.tensor([t], device<span class="op">=</span>z.device).repeat(n_samples)</span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>            beta_t <span class="op">=</span> scheduler.beta.to(<span class="va">self</span>.device)[t_tensor].view(n_samples, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> beta_t</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a>            hat_alpha_t <span class="op">=</span> scheduler.alpha.to(<span class="va">self</span>.device)[t_tensor].view(n_samples, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a>            <span class="co"># CORRECTED SAMPLING FORMULA</span></span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a>            predicted_noise <span class="op">=</span> <span class="va">self</span>.model(z, t_tensor, y)</span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> torch.sqrt(alpha_t)) <span class="op">*</span> (z <span class="op">-</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_t) <span class="op">/</span> torch.sqrt(<span class="dv">1</span> <span class="op">-</span> hat_alpha_t)) <span class="op">*</span> predicted_noise)</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> t <span class="op">&gt;</span> <span class="dv">1</span>:  <span class="co"># Only add noise if not the last step</span></span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> deterministic:</span>
<span id="cb24-83"><a href="#cb24-83" aria-hidden="true" tabindex="-1"></a>                    e <span class="op">=</span> <span class="va">self</span>.fixed_noise_seq[t].clone().to(<span class="va">self</span>.device)</span>
<span id="cb24-84"><a href="#cb24-84" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb24-85"><a href="#cb24-85" aria-hidden="true" tabindex="-1"></a>                    e <span class="op">=</span> torch.randn_like(z)</span>
<span id="cb24-86"><a href="#cb24-86" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> z <span class="op">+</span> torch.sqrt(beta_t) <span class="op">*</span> e</span>
<span id="cb24-87"><a href="#cb24-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-88"><a href="#cb24-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> z.clamp(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb24-89"><a href="#cb24-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-90"><a href="#cb24-90" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_train_epoch_end(<span class="va">self</span>):</span>
<span id="cb24-91"><a href="#cb24-91" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Log generated samples to W&amp;B every few epochs&quot;&quot;&quot;</span></span>
<span id="cb24-92"><a href="#cb24-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.current_epoch <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:  <span class="co"># Log every 5 epochs to reduce overhead</span></span>
<span id="cb24-93"><a href="#cb24-93" aria-hidden="true" tabindex="-1"></a>            imgs <span class="op">=</span> <span class="va">self</span>.generate_samples(n_samples<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb24-94"><a href="#cb24-94" aria-hidden="true" tabindex="-1"></a>            grid <span class="op">=</span> make_grid(imgs, nrow<span class="op">=</span><span class="dv">4</span>, normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-95"><a href="#cb24-95" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.logger.experiment.log({</span>
<span id="cb24-96"><a href="#cb24-96" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;generated_samples&quot;</span>: [wandb.Image(grid, caption<span class="op">=</span><span class="ss">f&quot;Epoch </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>current_epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&quot;</span>)]</span>
<span id="cb24-97"><a href="#cb24-97" aria-hidden="true" tabindex="-1"></a>            })</span></code></pre></div>
</div>
<div id="efd704fb" class="cell markdown" id="efd704fb">
<p>We now train our conditional model.<br />
Although we could load the previously trained (unconditional) model
weights, training this version from scratch is fast enough ‚Äî especially
on the MNIST dataset ‚Äî so we‚Äôll simply retrain it entirely.</p>
</div>
<div id="01d4e3ed" class="cell code" data-execution_count="21"
data-executionInfo="{&quot;elapsed&quot;:2281153,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554988,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="01d4e3ed">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>num_workers <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>num_time_steps <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">2e-5</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">&quot;./data&quot;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span>num_workers, drop_last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co"># W&amp;B logger</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>wandb_logger <span class="op">=</span> WandbLogger(project<span class="op">=</span><span class="st">&quot;lab8-diffusion&quot;</span>,</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>                           entity<span class="op">=</span><span class="st">&quot;deep-neural-network-course&quot;</span>,</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>                           group<span class="op">=</span><span class="st">&quot;conditional-diffusion-model&quot;</span>,</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>                           name<span class="op">=</span> <span class="st">&quot;Jan Rosa- conditional&quot;</span>,</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>                           log_model<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Model + Trainer setup</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ConditionalDiffusionModel(num_time_steps<span class="op">=</span>num_time_steps, lr<span class="op">=</span>lr)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>checkpoint_callback <span class="op">=</span> ModelCheckpoint(</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>        dirpath<span class="op">=</span><span class="st">&quot;./checkpoints&quot;</span>,</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>        filename<span class="op">=</span><span class="st">&quot;conditional-diffusion-</span><span class="sc">{epoch:02d}</span><span class="st">-</span><span class="sc">{train_loss:.4f}</span><span class="st">&quot;</span>,</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>        save_top_k<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        monitor<span class="op">=</span><span class="st">&quot;train_loss&quot;</span>,</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>        mode<span class="op">=</span><span class="st">&quot;min&quot;</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> L.Trainer(</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    max_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>    precision<span class="op">=</span><span class="st">&quot;16-mixed&quot;</span>,</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    logger<span class="op">=</span>wandb_logger,</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[checkpoint_callback],</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    log_every_n_steps<span class="op">=</span><span class="dv">50</span></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>trainer.fit(model, train_loader)</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>wandb.finish()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
</code></pre>
</div>
<div class="output display_data">

</div>
<div class="output display_data">
Tracking run with wandb version 0.22.3
</div>
<div class="output display_data">
Run data is saved locally in <code>./wandb/run-20251106_203809-bgjnhyy2</code>
</div>
<div class="output display_data">
Syncing run <strong><a href='https://wandb.ai/deep-neural-network-course/lab8-diffusion/runs/bgjnhyy2' target="_blank">Jan Rosa- conditional</a></strong> to <a href='https://wandb.ai/deep-neural-network-course/lab8-diffusion' target="_blank">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target="_blank">docs</a>)<br>
</div>
<div class="output display_data">
 View project at <a href='https://wandb.ai/deep-neural-network-course/lab8-diffusion' target="_blank">https://wandb.ai/deep-neural-network-course/lab8-diffusion</a>
</div>
<div class="output display_data">
 View run at <a href='https://wandb.ai/deep-neural-network-course/lab8-diffusion/runs/bgjnhyy2' target="_blank">https://wandb.ai/deep-neural-network-course/lab8-diffusion/runs/bgjnhyy2</a>
</div>
<div class="output stream stderr">
<pre><code>/home/jrosa/AGH_FILES/GSN-2025W/.venv/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/jrosa/AGH_FILES/GSN-2025W/lab_07_diff/checkpoints exists and is not empty.
/home/jrosa/AGH_FILES/GSN-2025W/.venv/lib/python3.10/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name      | Type            | Params | Mode 
------------------------------------------------------
0 | model     | ConditionalUNET | 36.9 M | train
1 | scheduler | DDPM_Scheduler  | 0      | train
2 | criterion | MSELoss         | 0      | train
------------------------------------------------------
36.9 M    Trainable params
0         Non-trainable params
36.9 M    Total params
147.508   Total estimated model params size (MB)
167       Modules in train mode
0         Modules in eval mode
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 937/937 [12:29&lt;00:00,  1.25it/s, v_num=hyy2, train_loss_step=0.0304, train_loss_epoch=0.0202] </code></pre>
</div>
<div class="output stream stderr">
<pre><code>`Trainer.fit` stopped: `max_epochs=3` reached.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 937/937 [12:30&lt;00:00,  1.25it/s, v_num=hyy2, train_loss_step=0.0304, train_loss_epoch=0.0202]
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>wandb: ERROR The nbformat package was not found. It is required to save notebook history.
</code></pre>
</div>
<div class="output display_data">

</div>
<div class="output display_data">
<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br/><table class="wandb"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss_epoch</td><td>‚ñà‚ñÇ‚ñÅ</td></tr><tr><td>train_loss_step</td><td>‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>trainer/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class="wandb-col"><h3>Run summary:</h3><br/><table class="wandb"><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss_epoch</td><td>0.02022</td></tr><tr><td>train_loss_step</td><td>0.0203</td></tr><tr><td>trainer/global_step</td><td>2810</td></tr></table><br/></div></div>
</div>
<div class="output display_data">
 View run <strong style="color:#cdcd00">Jan Rosa- conditional</strong> at: <a href='https://wandb.ai/deep-neural-network-course/lab8-diffusion/runs/bgjnhyy2' target="_blank">https://wandb.ai/deep-neural-network-course/lab8-diffusion/runs/bgjnhyy2</a><br> View project at: <a href='https://wandb.ai/deep-neural-network-course/lab8-diffusion' target="_blank">https://wandb.ai/deep-neural-network-course/lab8-diffusion</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
</div>
<div class="output display_data">
Find logs at: <code>./wandb/run-20251106_203809-bgjnhyy2/logs</code>
</div>
</div>
<div id="060ae86d" class="cell markdown" id="060ae86d">
<p>Load conditional model weights and test result on defined
<code>y</code> tensor.</p>
</div>
<div id="58472b17" class="cell code" data-execution_count="23"
data-executionInfo="{&quot;elapsed&quot;:2281153,&quot;status&quot;:&quot;aborted&quot;,&quot;timestamp&quot;:1762158554990,&quot;user&quot;:{&quot;displayName&quot;:&quot;JAN ROSA&quot;,&quot;userId&quot;:&quot;09972594920799623787&quot;},&quot;user_tz&quot;:-60}"
id="58472b17">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ConditionalDiffusionModel.load_from_checkpoint(<span class="st">&#39;checkpoints/conditional-diffusion-epoch=49-train_loss=0.0132.ckpt&#39;</span>, map_location<span class="op">=</span>device)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">7</span>, <span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>], device<span class="op">=</span>device)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> model.generate_samples(deterministic<span class="op">=</span><span class="va">False</span>, y<span class="op">=</span>y)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> make_grid(out, nrow<span class="op">=</span><span class="dv">4</span>, normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> grid.cpu().permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).numpy()</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(grid)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="8e2f9816726b2505c1f908240b4cf5142ed06071.png" /></p>
</div>
</div>
<div id="43d89525" class="cell code">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>python3 <span class="op">-</span>m jupyter nbconvert <span class="op">--</span>to html <span class="st">&quot;diffusion_todo.ipynb&quot;</span></span></code></pre></div>
</div>
</body>
</html>
